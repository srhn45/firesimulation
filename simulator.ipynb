{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4252f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from math import exp, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a622a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture_field(size, n_components=None):\n",
    "    x, y = np.meshgrid(np.linspace(0, 1, size), np.linspace(0, 1, size))\n",
    "    field = np.zeros((size, size))\n",
    "\n",
    "    if not n_components:\n",
    "        n_components = np.random.poisson(20)\n",
    "\n",
    "    for _ in range(n_components):\n",
    "        cx, cy = np.random.uniform(0, 1, 2) # random center\n",
    "        sx, sy = np.random.uniform(0.01, 0.2, 2) # random covariance scale\n",
    "        w = np.random.exponential(10) # weight scale\n",
    "\n",
    "        gaussian = w * np.exp(-(((x - cx) ** 2) / (2 * sx**2) +\n",
    "                                ((y - cy) ** 2) / (2 * sy**2)))\n",
    "        field += gaussian\n",
    "\n",
    "    field = (1 - (field - field.min()) / (field.max() - field.min()))*2\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator():\n",
    "    def __init__(self, size=256, wind_speed=0, wind_direction=[0,0], response_rate=0.1, response_start=20, base_spread_rate=0.3, n_components=None, decay_rate=1e-3):\n",
    "        self.size = size\n",
    "        self.map = np.zeros((size, size))\n",
    "        self.wind_speed = wind_speed\n",
    "        self.wind_direction = wind_direction\n",
    "        self.response_rate = response_rate\n",
    "        self.response_start = response_start\n",
    "        self.spread_rate = base_spread_rate\n",
    "        self.time = 0\n",
    "        self.decay_rate = decay_rate\n",
    "        self.maps = {}\n",
    "\n",
    "        self.terrain = gaussian_mixture_field(size, n_components=n_components)\n",
    "\n",
    "    def step(self):\n",
    "        new_map = deepcopy(self.map)\n",
    "\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if self.map[i, j] >= 1:\n",
    "                    if np.random.rand() < self.spread_rate*self.terrain[i, j]*np.exp(-self.decay_rate * self.time) and new_map[i, j] < 5:\n",
    "                        new_map[i, j] += 1\n",
    "                    \n",
    "                    for di in [-1, 0, 1]:\n",
    "                        for dj in [-1, 0, 1]:\n",
    "                            if di == 0 and dj == 0:\n",
    "                                continue\n",
    "\n",
    "                            ni, nj = i + di, j + dj\n",
    "                            spread_chance = self.spread_rate*self.map[i,j]\n",
    "\n",
    "                            if 0 <= ni < self.size and 0 <= nj < self.size:\n",
    "                                if self.wind_speed > 0:\n",
    "                                    wind_influence = (di * self.wind_direction[0] + dj * self.wind_direction[1]) / (np.linalg.norm(self.wind_direction) + 1e-6)\n",
    "                                    wind_influence *= np.random.normal(1, 0.5)\n",
    "\n",
    "\n",
    "                                    if wind_influence > 0:\n",
    "                                        spread_chance *= (1 + self.wind_speed * wind_influence)\n",
    "                                    spread_chance *= self.terrain[ni, nj]\n",
    "                                    spread_chance *= np.exp(-self.decay_rate * self.time)\n",
    "                                    spread_chance = np.clip(spread_chance, 0, 1)\n",
    "\n",
    "                                if np.random.rand() < spread_chance and new_map[ni, nj] <= new_map[i, j]:\n",
    "                                    if new_map[ni, nj] < 5:\n",
    "                                        if np.random.rand() <= exp(-self.time/1000):\n",
    "                                            new_map[ni, nj] += 1\n",
    "\n",
    "                                if self.time >= self.response_start and new_map[ni, nj] == 0:\n",
    "                                    if np.random.rand() < 1 - exp(-(self.response_rate*(0.5+self.terrain[i,j]) * (self.time - self.response_start))):\n",
    "                                        if new_map[i, j] > 0:\n",
    "                                            new_map[i, j] -= 1 # Firefighting effort\n",
    "                            if np.exp(-self.decay_rate * self.time) < 0.5:\n",
    "                                if ni < 0 or ni >= self.size or nj < 0 or nj >= self.size:\n",
    "                                    if np.random.rand() < 1 - exp(-(self.response_rate) * (self.time - self.response_start)):\n",
    "                                        if new_map[i, j] > 0:\n",
    "                                            new_map[i, j] -= 1 # Edge effect\n",
    "                    \n",
    "                else:\n",
    "                    if 1 < i < self.size - 1 and 1 < j < self.size - 1:\n",
    "                        neighbors_on_fire = np.sum(self.map[i-1:i+2, j-1:j+2] >= 1) - (1 if self.map[i, j] >= 1 else 0)\n",
    "                        if neighbors_on_fire >= 6 and new_map[i, j] == 0:\n",
    "                            new_map[i, j] += 1\n",
    "        \n",
    "        self.maps[self.time] = deepcopy(self.map)\n",
    "        self.map = new_map\n",
    "        self.time += 1\n",
    "\n",
    "    def simulate(self):\n",
    "        nodes = np.random.poisson(3)\n",
    "\n",
    "        x_init, y_init = np.random.randint(0, self.size, size=2)\n",
    "        self.map[x_init, y_init] = np.random.poisson(3)\n",
    "\n",
    "        for _ in range(nodes - 1):\n",
    "            while True:\n",
    "                x, y = np.random.randint(-20, 21, size=2)\n",
    "                if x_init+x < self.size and y_init+y < self.size:\n",
    "                    break\n",
    "                \n",
    "            if self.map[x_init+x, y_init+y] == 0:\n",
    "                self.map[x_init+x, y_init+y] = np.random.poisson(3)\n",
    "                break\n",
    "    \n",
    "        while np.any(self.map > 0):\n",
    "            self.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa1fba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(size=256, wind_speed=1.5, wind_direction=[1,2], response_rate=0.05, response_start=100, base_spread_rate=0.05)\n",
    "simulator.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d70e6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap_gif(simulator, filename=\"simulation.gif\", cmap=\"plasma\"):\n",
    "    times = sorted(simulator.maps.keys())\n",
    "    frames = [simulator.maps[t] for t in times]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # --- fire as background ---\n",
    "    vmin, vmax = np.min(frames), np.max(frames)\n",
    "    fire_img = ax.imshow(frames[0], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    # --- terrain overlay ---\n",
    "    terrain_img = ax.imshow(simulator.terrain, cmap=\"Greens\", alpha=0.2)  # low alpha on top\n",
    "\n",
    "    cbar = fig.colorbar(fire_img, ax=ax)\n",
    "    cbar.set_label(\"Fire Intensity\", rotation=270, labelpad=15)\n",
    "\n",
    "    def update(frame):\n",
    "        fire_img.set_data(frame)    \n",
    "        return [fire_img, terrain_img]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, update, frames=frames, interval=60, blit=True\n",
    "    )\n",
    "\n",
    "    ani.save(filename, writer=\"pillow\")\n",
    "    plt.close(fig)\n",
    "\n",
    "make_heatmap_gif(simulator, \"fire.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926e290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One approach could be using GNN's, which would result in a scalable network to different grid sizes\n",
    "# Another is to use a transformer, easier to train\n",
    "# I'm going to try a Graph Attention Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from scipy.sparse import lil_matrix\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9430ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix(length, width):\n",
    "    N = length * width\n",
    "    adj = lil_matrix((N, N), dtype=np.float32)\n",
    "    directions = [(-1,0), (-1,1), (0,1), (1,1), (1,0), (1,-1), (0,-1), (-1,-1), (0,0)] # 8 sided\n",
    "    for i in range(N):\n",
    "        x, y = divmod(i, width)\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x+dx, y+dy\n",
    "            if 0 <= nx < length and 0 <= ny < width:\n",
    "                j = nx*width + ny\n",
    "                adj[i,j] = 1\n",
    "    return adj.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireGraph(Dataset):\n",
    "    def __init__(self, length=256, width=256, path=\"/simulation_data\"):\n",
    "        self.path = path\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "\n",
    "\n",
    "        adj = adjacency_matrix(self.length, self.width)\n",
    "        self.adjacency_matrix = torch.sparse_coo_tensor(\n",
    "            indices=torch.tensor(np.vstack((adj.row, adj.col)), dtype=torch.long),\n",
    "            values=torch.tensor(adj.data, dtype=torch.float32),\n",
    "            size=adj.shape\n",
    "        )\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        self.save_dir = os.path.join(self.path, f\"{self.length}x{self.width}\")\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def generate_data(self, topology:np.array=None, past_info:np.array=None, wind_direction:np.array=np.array([0,0]),\n",
    "                         wind_speed:int=0, time:int=0, label:np.array=None):\n",
    "        \n",
    "        flat_topo = topology.ravel()\n",
    "        flat_info = past_info[:, :, 0].ravel()\n",
    "        flat_info_date = past_info[:, :, 1].ravel()\n",
    "        flat_label = label.ravel()\n",
    "        \n",
    "        data = np.stack([\n",
    "            flat_topo,\n",
    "            flat_info,\n",
    "            flat_info_date,\n",
    "            np.full(flat_topo.shape, wind_direction[0], dtype=np.float32),\n",
    "            np.full(flat_topo.shape, wind_direction[1], dtype=np.float32),\n",
    "            np.full(flat_topo.shape, wind_speed, dtype=np.float32),\n",
    "            np.full(flat_topo.shape, time, dtype=np.float32),\n",
    "            flat_label\n",
    "        ], axis=1)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def save_data(self, data:np.array):\n",
    "        np.save(os.path.join(self.save_dir, f\"{time.time():.0f}.npy\"), data)\n",
    "    \n",
    "    def generate_dataset(self):\n",
    "        arrays = []\n",
    "        for file in os.listdir(self.save_dir):\n",
    "            if file.endswith(\".npy\"):\n",
    "                arr = np.load(os.path.join(self.save_dir, file))\n",
    "                arrays.append(arr)\n",
    "\n",
    "        if arrays:\n",
    "            self.data = np.concatenate(arrays, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.data[idx]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referenced https://github.com/gordicaleksa/pytorch-GAT/blob/main/The%20Annotated%20GAT%20(Cora).ipynb for some of the code.\n",
    "\n",
    "class BelieverModel(nn.Module):\n",
    "    def __init__(self, nodes=256*256, input_features=7, num_layers=3, num_heads=3, num_features_per_head=4, num_output_classes=5, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.N = nodes\n",
    "        self.num_heads = num_heads\n",
    "        self.num_features_per_head = num_features_per_head\n",
    "\n",
    "        self.initial_transformation = nn.Linear(input_features, num_heads * num_features_per_head, bias=False)\n",
    "        nn.init.xavier_normal_(self.initial_transformation.weight)\n",
    "\n",
    "        self.a_lefts = nn.ParameterList()\n",
    "        self.a_rights = nn.ParameterList()\n",
    "        self.Ws = nn.ParameterList()\n",
    "        for i in range(num_layers):\n",
    "            a_left = nn.Parameter(torch.zeros(size=(num_heads, num_features_per_head)))\n",
    "            nn.init.xavier_uniform_(a_left)\n",
    "            a_right = nn.Parameter(torch.zeros(size=(num_heads, num_features_per_head)))\n",
    "            nn.init.xavier_uniform_(a_right)\n",
    "            W = nn.Parameter(torch.zeros(size=(num_heads, num_features_per_head, num_features_per_head)))\n",
    "            nn.init.xavier_normal_(W)\n",
    "\n",
    "            self.a_lefts.append(a_left)\n",
    "            self.a_rights.append(a_right)\n",
    "            self.Ws.append(W)\n",
    "        \n",
    "        self.final_transformation = nn.Linear(num_heads*num_features_per_head, num_output_classes)\n",
    "        nn.init.xavier_normal_(self.final_transformation.weight)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        # adj = (N, N) adjacency matrix, in coo matrix format\n",
    "        # x = inputs (N, F_in)\n",
    "\n",
    "        # x = self.dropout(x)\n",
    "        N = x.size(0)\n",
    "        x = self.initial_transformation(x) # (N, F_out*H)\n",
    "        x = x.view(N, self.num_heads, self.num_features_per_head) # (N, H, F_out)\n",
    "\n",
    "        for W, a_left, a_right in zip(self.Ws, self.a_lefts, self.a_rights):\n",
    "            # W = (H, F_out, F_out)\n",
    "            # a_left = (H, F_out)\n",
    "            # a_right = (H, F_out)\n",
    "\n",
    "            # alpha_i,j = exp(a * [h_i||h_j] * adj[i,j]) / sum_j(exp(a * [h_i||h_j] * adj[i,j])), softmax\n",
    "            # h(i') = adj * sum_j (alpha_i,j * W * h_j)\n",
    "            # to simplify, we split a into 2 parts a_left and a_right, and calculate the attention scores for each of those parts, then sum up the scores only for viable pairs for computational efficiency\n",
    "\n",
    "            h_prime = torch.einsum(\"nhf,hfo->nho\", x, W) # (N, H, F_out) x (H, F_out, F_out) -> (N, H, F_out)\n",
    "\n",
    "            source_scores = (h_prime * a_left).sum(-1) # elementwise product, (N, H)\n",
    "            neighbor_scores = (h_prime * a_right).sum(-1) # (N, H)\n",
    "\n",
    "            row, col = adj.indices()\n",
    "            row = row.long(); col = col.long()\n",
    "            e = self.leakyrelu(source_scores[row] + neighbor_scores[col]) # (E, H) where E is the number of edges\n",
    "\n",
    "            H =e.size(1)\n",
    "            if hasattr(torch.Tensor, \"scatter_reduce\"):\n",
    "                max_per_node = torch.zeros((N, H), device=e.device, dtype=e.dtype).scatter_reduce(\n",
    "                    0, row.unsqueeze(-1).expand(-1,H), e, reduce=\"amax\", include_self=False\n",
    "                ) # maximum score among all neighbors of node i, (N, H)\n",
    "            else:\n",
    "                # fallback: compute max per node manually (safe but slower)\n",
    "                max_per_node = torch.full((N,H), -1e9, device=e.device, dtype=e.dtype)\n",
    "                for i_edge, i_node in enumerate(row):\n",
    "                    max_per_node[i_node] = torch.maximum(max_per_node[i_node], e[i_edge])\n",
    "            exp_e = torch.exp(e - max_per_node[row]) # for numerical stability, (E, H)\n",
    "\n",
    "            denom = torch.zeros((N, H), device=e.device, dtype=e.dtype)\n",
    "            denom.index_add_(0, row, exp_e) # summation over neighbors, (N, H)\n",
    "\n",
    "            alpha = exp_e / (denom[row] + 1e-9) # elementwise division, (E, H)\n",
    "\n",
    "            messages = h_prime[col] * alpha.unsqueeze(-1) # (E, H, F)\n",
    "\n",
    "            out = torch.zeros_like(h_prime, device=h_prime.device, dtype=h_prime.dtype)\n",
    "            out.index_add_(0, row, messages) # summation over neighbors again, (N, H, F)\n",
    "            x = out\n",
    "        \n",
    "        x = x.reshape(N, self.num_heads * self.num_features_per_head)\n",
    "        logits = self.final_transformation(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator():\n",
    "    def __init__(self, size=256, wind_speed=1.5, wind_direction=[1,2], response_rate=0.05, response_start=100, base_spread_rate=0.05, perturb=True):\n",
    "        self.size = size\n",
    "        self.wind_speed = wind_speed\n",
    "        self.wind_direction = wind_direction\n",
    "        self.response_rate = response_rate\n",
    "        self.response_start = response_start\n",
    "        self.base_spread_rate = base_spread_rate\n",
    "        self.perturb = perturb\n",
    "        self.dataset = FireGraph(length=self.size, width=self.size)\n",
    "\n",
    "    def generate(self, num_sims=100, std_dev=0.2):\n",
    "        for i in range(num_sims):\n",
    "            if self.perturb:\n",
    "                \n",
    "                simulator = Simulator(size=self.size, wind_speed=np.random.normal(self.wind_speed, std_dev*self.wind_speed), wind_direction=[np.random.uniform(-1, 1), np.random.uniform(-1,1)], \n",
    "                    response_rate=max(np.random.normal(self.response_rate, std_dev*self.response_rate), 0.005),\n",
    "                    response_start=max(np.random.normal(self.response_start, math.floor(std_dev*self.response_start)), 0), \n",
    "                    base_spread_rate=max(np.random.normal(self.base_spread_rate, std_dev*self.base_spread_rate), 0),\n",
    "                )\n",
    "            else:\n",
    "                simulator = Simulator(size=self.size, wind_speed=self.wind_speed, wind_direction=self.wind_direction, response_rate=self.response_rate, \n",
    "                    response_start=self.response_start, base_spread_rate=self.base_spread_rate)\n",
    "                \n",
    "            simulator.simulate()\n",
    "\n",
    "            simulation_data = []\n",
    "            past_info = np.zeros((self.size, self.size, 2))\n",
    "            for t in simulator.maps:\n",
    "                if 0.5 > np.random.rand():\n",
    "                    coords = np.random.randint(0, 256, 2)\n",
    "                    if t>0:\n",
    "                        prev_map = simulator.maps[t-1]\n",
    "                        y_min, y_max = max(0, coords[0]-3), min(self.size, coords[0]+4)\n",
    "                        x_min, x_max = max(0, coords[1]-3), min(self.size, coords[1]+4)\n",
    "\n",
    "                        past_info[y_min:y_max, x_min:x_max, 0] = prev_map[y_min:y_max, x_min:x_max]\n",
    "                        past_info[y_min:y_max, x_min:x_max, 1] = 0     \n",
    "\n",
    "                    past_info[:, :, 1] += 1\n",
    "\n",
    "                \n",
    "                data_point = self.dataset.generate_data(topology=simulator.terrain, past_info=past_info, wind_direction=np.array(simulator.wind_direction), \n",
    "                                           wind_speed=simulator.wind_speed, time=t, label=simulator.maps[t])\n",
    "                simulation_data.append(data_point)\n",
    "                \n",
    "            self.dataset.save_data(np.array(simulation_data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
