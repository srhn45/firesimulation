{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4252f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from math import exp, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a622a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture_field(size, n_components=None):\n",
    "    x, y = np.meshgrid(np.linspace(0, 1, size), np.linspace(0, 1, size))\n",
    "    field = np.zeros((size, size))\n",
    "\n",
    "    if not n_components:\n",
    "        n_components = np.random.poisson(20)\n",
    "\n",
    "    for _ in range(n_components):\n",
    "        cx, cy = np.random.uniform(0, 1, 2) # random center\n",
    "        sx, sy = np.random.uniform(0.01, 0.2, 2) # random covariance scale\n",
    "        w = np.random.exponential(10) # weight scale\n",
    "\n",
    "        gaussian = w * np.exp(-(((x - cx) ** 2) / (2 * sx**2) +\n",
    "                                ((y - cy) ** 2) / (2 * sy**2)))\n",
    "        field += gaussian\n",
    "\n",
    "    field = (1 - (field - field.min()) / (field.max() - field.min()))*2\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator():\n",
    "    def __init__(self, size=256, wind_speed=0, wind_direction=[0,0], response_rate=0.1, response_start=20, base_spread_rate=0.3, n_components=None, decay_rate=1e-3):\n",
    "        self.size = size\n",
    "        self.map = np.zeros((size, size))\n",
    "        self.wind_speed = wind_speed\n",
    "        self.wind_direction = wind_direction\n",
    "        self.response_rate = response_rate\n",
    "        self.response_start = response_start\n",
    "        self.spread_rate = base_spread_rate\n",
    "        self.time = 0\n",
    "        self.decay_rate = decay_rate\n",
    "        self.maps = {}\n",
    "\n",
    "        self.terrain = gaussian_mixture_field(size, n_components=n_components)\n",
    "\n",
    "    def step(self):\n",
    "        new_map = deepcopy(self.map)\n",
    "\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if self.map[i, j] >= 1:\n",
    "                    if np.random.rand() < self.spread_rate*self.terrain[i, j]*np.exp(-self.decay_rate * self.time) and new_map[i, j] < 5:\n",
    "                        new_map[i, j] += 1\n",
    "                    \n",
    "                    for di in [-1, 0, 1]:\n",
    "                        for dj in [-1, 0, 1]:\n",
    "                            if di == 0 and dj == 0:\n",
    "                                continue\n",
    "\n",
    "                            ni, nj = i + di, j + dj\n",
    "                            spread_chance = self.spread_rate*self.map[i,j]\n",
    "\n",
    "                            if 0 <= ni < self.size and 0 <= nj < self.size:\n",
    "                                if self.wind_speed > 0:\n",
    "                                    wind_influence = (di * self.wind_direction[0] + dj * self.wind_direction[1]) / (np.linalg.norm(self.wind_direction) + 1e-6)\n",
    "                                    wind_influence *= np.random.normal(1, 0.5)\n",
    "\n",
    "\n",
    "                                    if wind_influence > 0:\n",
    "                                        spread_chance *= (1 + self.wind_speed * wind_influence)\n",
    "                                    spread_chance *= self.terrain[ni, nj]\n",
    "                                    spread_chance *= np.exp(-self.decay_rate * self.time)\n",
    "                                    spread_chance = np.clip(spread_chance, 0, 1)\n",
    "\n",
    "                                if np.random.rand() < spread_chance and new_map[ni, nj] <= new_map[i, j]:\n",
    "                                    if new_map[ni, nj] < 5:\n",
    "                                        if np.random.rand() <= exp(-self.time/1000):\n",
    "                                            new_map[ni, nj] += 1\n",
    "\n",
    "                                if self.time >= self.response_start and new_map[ni, nj] == 0:\n",
    "                                    if np.random.rand() < 1 - exp(-(self.response_rate*(0.5+self.terrain[i,j]) * (self.time - self.response_start))):\n",
    "                                        if new_map[i, j] > 0:\n",
    "                                            new_map[i, j] -= 1 # Firefighting effort\n",
    "                            if np.exp(-self.decay_rate * self.time) < 0.5:\n",
    "                                if ni < 0 or ni >= self.size or nj < 0 or nj >= self.size:\n",
    "                                    if np.random.rand() < 1 - exp(-(self.response_rate) * (self.time - self.response_start)):\n",
    "                                        if new_map[i, j] > 0:\n",
    "                                            new_map[i, j] -= 1 # Edge effect\n",
    "                    \n",
    "                else:\n",
    "                    if 1 < i < self.size - 1 and 1 < j < self.size - 1:\n",
    "                        neighbors_on_fire = np.sum(self.map[i-1:i+2, j-1:j+2] >= 1) - (1 if self.map[i, j] >= 1 else 0)\n",
    "                        if neighbors_on_fire >= 6 and new_map[i, j] == 0:\n",
    "                            new_map[i, j] += 1\n",
    "        \n",
    "        self.maps[self.time] = deepcopy(self.map)\n",
    "        self.map = new_map\n",
    "        self.time += 1\n",
    "\n",
    "    def simulate(self):\n",
    "        nodes = np.random.poisson(3)\n",
    "\n",
    "        x_init, y_init = np.random.randint(0, self.size, size=2)\n",
    "        self.map[x_init, y_init] = np.random.poisson(3)\n",
    "\n",
    "        for _ in range(nodes - 1):\n",
    "            while True:\n",
    "                x, y = np.random.randint(-20, 21, size=2)\n",
    "                if x_init+x < self.size and y_init+y < self.size:\n",
    "                    break\n",
    "                \n",
    "            if self.map[x_init+x, y_init+y] == 0:\n",
    "                self.map[x_init+x, y_init+y] = np.random.poisson(3)\n",
    "                break\n",
    "    \n",
    "        while np.any(self.map > 0):\n",
    "            self.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa1fba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(size=256, wind_speed=1.5, wind_direction=[1,2], response_rate=0.05, response_start=100, base_spread_rate=0.05)\n",
    "simulator.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d70e6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap_gif(simulator, filename=\"simulation.gif\", cmap=\"plasma\"):\n",
    "    times = sorted(simulator.maps.keys())\n",
    "    frames = [simulator.maps[t] for t in times]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # --- fire as background ---\n",
    "    vmin, vmax = np.min(frames), np.max(frames)\n",
    "    fire_img = ax.imshow(frames[0], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    # --- terrain overlay ---\n",
    "    terrain_img = ax.imshow(simulator.terrain, cmap=\"Greens\", alpha=0.2)  # low alpha on top\n",
    "\n",
    "    cbar = fig.colorbar(fire_img, ax=ax)\n",
    "    cbar.set_label(\"Fire Intensity\", rotation=270, labelpad=15)\n",
    "\n",
    "    def update(frame):\n",
    "        fire_img.set_data(frame)    \n",
    "        return [fire_img, terrain_img]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, update, frames=frames, interval=60, blit=True\n",
    "    )\n",
    "\n",
    "    ani.save(filename, writer=\"pillow\")\n",
    "    plt.close(fig)\n",
    "\n",
    "make_heatmap_gif(simulator, \"fire.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926e290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One approach could be using GNN's, which would result in a scalable network to different grid sizes\n",
    "# Another is to use a transformer, easier to train\n",
    "# I'm going to try a Graph Attention Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9545a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from scipy.sparse import lil_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9430ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix(length, width):\n",
    "    N = length * width\n",
    "    adj = lil_matrix((N, N), dtype=np.float32)\n",
    "    directions = [(-1,0), (-1,1), (0,1), (1,1), (1,0), (1,-1), (0,-1), (-1,-1), (0,0)] # 8 sided\n",
    "    for i in range(N):\n",
    "        x, y = divmod(i, width)\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x+dx, y+dy\n",
    "            if 0 <= nx < length and 0 <= ny < width:\n",
    "                j = nx*width + ny\n",
    "                adj[i,j] = 1\n",
    "    return adj.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireGraph(Dataset):\n",
    "    def __init__(self, length=256, width=256, path=\"/simulation_data\"):\n",
    "        self.path = path\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "\n",
    "\n",
    "        adj = adjacency_matrix(self.length, self.width)\n",
    "        self.adjacency_matrix = torch.sparse_coo_tensor(\n",
    "            indices=torch.tensor(np.vstack((adj.row, adj.col)), dtype=torch.long),\n",
    "            values=torch.tensor(adj.data, dtype=torch.float32),\n",
    "            size=adj.shape\n",
    "        )\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        self.save_dir = os.path.join(self.path, f\"{self.length}x{self.width}\")\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def generate_data(self, topology:np.array=None, past_info:np.array=None, wind_direction:np.array=np.array([0,0]),\n",
    "                         wind_speed:int=0, time:int=0, label:np.array=None):\n",
    "        \n",
    "        flat_topo = topology.ravel()\n",
    "        flat_info = past_info[:, :, 0].ravel()\n",
    "        flat_info_date = past_info[:, :, 1].ravel()\n",
    "        flat_label = label.ravel()\n",
    "        \n",
    "        data = np.stack([\n",
    "            flat_topo,\n",
    "            flat_info,\n",
    "            flat_info_date,\n",
    "            np.full(flat_topo.shape, wind_direction[0], dtype=np.float32),\n",
    "            np.full(flat_topo.shape, wind_direction[1], dtype=np.float32),\n",
    "            np.full(flat_topo.shape, wind_speed, dtype=np.float32),\n",
    "            np.full(flat_topo.shape, time, dtype=np.float32),\n",
    "            flat_label\n",
    "        ], axis=1)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def save_data(self, data):\n",
    "        np.save(os.path.join(self.save_dir, f\"{time.time():.0f}.npy\"), data)\n",
    "    \n",
    "    def generate_dataset(self):\n",
    "        for file in os.listdir(self.save_dir):\n",
    "            if file.endswith(\".npy\"):\n",
    "                self.data.append(np.load(os.path.join(self.save_dir, file)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.data[idx]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BelieverModel(nn.Module):\n",
    "    def __init__(self, nodes=256*256, input_features=8, num_layers=3, num_heads=3, num_features_per_head=4, num_output_classes=5):\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.N = nodes\n",
    "\n",
    "        self.initial_transformation = nn.Parameter(torch.zeros(size=(input_features, num_features_per_head*num_heads)))\n",
    "        nn.init.xavier_normal(self.initial_transformation.data)\n",
    "\n",
    "        self.layers = []\n",
    "        for i in range(num_layers):\n",
    "            attention_vector = nn.Parameter(torch.zeros(size=(2*num_features_per_head*num_heads, num_heads, 1)))\n",
    "            nn.init.xavier_uniform(attention_vector.data)\n",
    "\n",
    "            W = nn.Parameter(torch.zeros(size=(num_features_per_head*num_heads, num_heads, num_features_per_head)))\n",
    "            nn.init.xavier_normal(W.data)\n",
    "\n",
    "            layer = { \n",
    "                \"a\" : attention_vector,\n",
    "                \"W\" : W \n",
    "                }\n",
    "            \n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.final_transformation = nn.Parameter(torch.zeros(num_heads*num_features_per_head, num_output_classes))\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        # adj = (N, N) adjacency matrix\n",
    "        # x = inputs (N, F_inputs)\n",
    "\n",
    "        x = self.relu(torch.chain_matmul(adj, x, self.initial_transformation)) # (N, F_in)\n",
    "\n",
    "        for _, layer in enumerate(self.layers):\n",
    "            outputs = []\n",
    "            for __, head in enumerate(layer):\n",
    "                W = head[\"W\"]                       # (F_in, F_out)\n",
    "                a = head[\"a\"]                       # (2*F_out, 1)\n",
    "\n",
    "                # compute pairwise attention scores \n",
    "                # expand for all pairs (i,j)\n",
    "                row, col = adj.indices()\n",
    "\n",
    "                x_i = x[row]  # (E, F_out), E is the number of viable pairs.\n",
    "                x_j = x[col]  # (E, F_out)\n",
    "                attn_input = torch.cat([x_i, x_j], dim=1)  # (E, 2*F_out)\n",
    "\n",
    "                e = self.leakyrelu(attn_input @ a).squeeze(-1) # (E, ) # vector of attention scores\n",
    "\n",
    "                # need to implement softmax, then the rest is easy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # linear transformation\n",
    "                h = x @ W                           # (N, F_out)\n",
    "\n",
    "                # adj@self.relu(attention scores @ W @ x)\n",
    "\n",
    "            x = torch.cat(outputs, dim=-1)  # concat heads, (N, num_heads*F_out)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
